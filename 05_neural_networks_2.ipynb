{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was inspired by neural network & machine learning labs led by [GMUM](https://gmum.net/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training neural networks\n",
    "\n",
    "There are three necessary ingredients in training neural networks:\n",
    "\n",
    "* the model,\n",
    "* the loss,\n",
    "* the optimizer.\n",
    "\n",
    "We've already implemented a popular loss function in the first lab. Last week we covered the most popular optimizers. Today we'll implement a custom model. \n",
    "\n",
    "First, however, we need to prepare the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (0.5p)\n",
    "Prepare the data (from the FashionMNIST dataset) which we'll be using for the next task.\n",
    "You need to, using [transforms](https://pytorch.org/vision/0.8/transforms.html) (following first week's notebook):\n",
    "- convert the PIL images to tensors,\n",
    "- calculate the mean and standard deviation of pixels of the training set and use that to normalize the training data (this is new),\n",
    "- change the shape of each image from 28x28 to 784."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ???\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculate_mean_and_std() -> Tuple[float, float]:\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        FashionMNIST(\n",
    "            root='.',\n",
    "            download=True,\n",
    "            train=True,\n",
    "            transform=ToTensor()\n",
    "        )\n",
    "    )\n",
    "    ???\n",
    "\n",
    "mean, std = calculate_mean_and_std()\n",
    "\n",
    "train_data = FashionMNIST(root='.', \n",
    "                          download=True, \n",
    "                          train=True, \n",
    "                          ???)\n",
    "\n",
    "test_data = FashionMNIST(root='.', \n",
    "                         download=True, \n",
    "                         train=False, \n",
    "                         ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell checks whether the mean and std calculation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(mean, 0.286, atol=1e-4)\n",
    "assert np.isclose(std, 0.353, atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell checks whether the dataloader returns objects of appropriate shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=10)\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "\n",
    "assert len(x.shape) == 2\n",
    "assert x.shape == (10, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now proceed to building our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (1p)\n",
    "Implement a simple neural network in PyTorch. \n",
    "\n",
    "The network is supposed to accept data of dimension `input_dim` and have one hidden layer of size `hidden_dim` with weights initialized from the standard normal distribution. The biases are supposed to be initialized with zeros. For the activation function for the first layer use `torch.tanh`. For the second layer use a linear activation function. Don't forget to use `requires_grad=True` when defining the parameters of the network.\n",
    "Next, implement a training loop in PyTorch utilizing the cost function `nn.CrossEntropyLoss` and the SGD optimizer.\n",
    "\n",
    "If everything was implemented correctly, the network should usually achieve accuracy higher than $80\\%$ on the test set (you might need a few runs for this depending on the initialization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class CustomNetwork(object):\n",
    "    \"\"\"\n",
    "    Simple 1-hidden-layer linear neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Initialize the network's weights \n",
    "        \"\"\"\n",
    "        self.weight_1: torch.Tensor = ???\n",
    "        self.bias_1: torch.Tensor = ???\n",
    "        \n",
    "        self.weight_2: torch.Tensor = ???\n",
    "        self.bias_2: torch.Tensor = ???\n",
    "\n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the network\n",
    "        \"\"\"\n",
    "        ???\n",
    "        \n",
    "    def parameters(self) -> List[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Return a list of all trainable parameters \n",
    "        \"\"\"\n",
    "        return [self.weight_1, self.bias_1, self.weight_2, self.bias_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell checks whether the network's weights have appropriate shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = CustomNetwork(100, 32, 54)\n",
    "\n",
    "assert network.weight_1.shape == (100, 32)\n",
    "assert network.weight_2.shape == (32, 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "# some hyperparams\n",
    "batch_size: int = 64\n",
    "n_epochs: int = 10\n",
    "\n",
    "# prepare data loaders, based on the already loaded datasets\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# initialize the model\n",
    "model: CustomNetwork = ???\n",
    "\n",
    "# initialize the optimizer using the hyperparams below\n",
    "lr: float = 0.01\n",
    "momentum: float = 0.9\n",
    "optimizer: torch.optim.Optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# training loop\n",
    "for e in range(n_epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        # reset the gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # pass through the network\n",
    "        output: torch.Tensor = ???\n",
    "        # calculate loss\n",
    "        loss: torch.Tensor = criterion(???)\n",
    "        # backward pass through the network\n",
    "        loss.backward()\n",
    "        # apply the gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # log the loss value\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"\\rEpoch {e+1} iter {i+1}/{len(train_data) // batch_size} loss: {loss.item()}\", end=\"\")\n",
    "            \n",
    "    # at the end of an epoch run evaluation on the test set\n",
    "    with torch.no_grad():\n",
    "        # initialize the number of correct predictions\n",
    "        correct: int = 0 \n",
    "        for i, (x, y) in enumerate(test_loader):\n",
    "            # pass through the network\n",
    "            output: torch.Tensor = ???\n",
    "            correct += ???\n",
    "\n",
    "        print(f\"\\nTest accuracy: {correct / len(test_data)}\")\n",
    "\n",
    "        \n",
    "# this is your test\n",
    "assert correct / len(test_data) > 0.8, \"Subject to random seed you should be able to get >80% accuracy\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
